{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to process BCDI data using cdiutils package and PyNX phase retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hdf5plugin # if data are too large\n",
    "from xrayutilities import en2lam\n",
    "\n",
    "from cdiutils.process.pipeline import BcdiPipeline\n",
    "from cdiutils.process.parameters import get_parameters_from_notebook_variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "metadata = {\n",
    "  \"beamline_setup\": \"\",  # Required\n",
    "  \"scan\": None,  # Required\n",
    "  \"sample_name\": \"\",  # Required for ID01BLISS, P10 and SIXS2022 setups\n",
    "  \"experiment_file_path\": \"\",  # Required for ID01SPEC, ID01BLISS setups\n",
    "  \"experiment_data_dir_path\": \"\",  # Required for P10 and SIXS2022 setups\n",
    "  \"detector_data_path\": \"\",  # Required for ID01SPEC setup\n",
    "  \"edf_file_template\": \"\",  # Required for ID01SPEC setup\n",
    "  \"detector_name\": \"\",  # Required\n",
    "  \"flatfield_path\": None,\n",
    "  \"alien_mask\": None,\n",
    "  \"dump_dir\": \"\",\n",
    "  \"reconstruction_file\": \"mode.h5\"\n",
    "}\n",
    "\n",
    "# Required, you choose, either you specify it in the metadata, or you\n",
    "# want the dump_dir to be dependent on the 'sample_name' and 'scan' or\n",
    "# other things.\n",
    "metadata[\"dump_dir\"] = (\n",
    "    os.getcwd() + f'/results/{metadata[\"sample_name\"]}/S{metadata[\"scan\"]}/'\n",
    ")\n",
    "\n",
    "preprocessing_output_shape = []  # Required, 2 or 3 values. If 2, will take the whole RC \n",
    "energy = None  # Required, in eV\n",
    "hkl = []  # Required\n",
    "\n",
    "# Required, must be a list of \"com\", \"max\" or tuple of int that corresponds\n",
    "# to the position you want to crop the data at. It can be 2D ! And you can\n",
    "# mix it with binning_along_axis0. \n",
    "det_reference_voxel_method = []\n",
    "binning_along_axis0 = None  # Whether or not you want to bin in the RC direction\n",
    "light_loading = False  # Load only the roi defined by the det_reference_voxel and preprocessing_output_shape\n",
    "binning_factors = (1, 1, 1)  # Binning in the 3 directions, mind that \n",
    "# preprocessing_output_shape and det_reference_voxel_method should be provided\n",
    "# accordingly.\n",
    "\n",
    "# Required\n",
    "det_calib_parameters = {\n",
    "  'cch1': 0,  # direct beam position vertical \n",
    "  'cch2': 0,  # horizontal\n",
    "  'pwidth1': 5.5e-05,  # detector pixel size in microns\n",
    "  'pwidth2': 5.5e-05,  # detector pixel size in microns\n",
    "  'distance': 0,  # sample to detector distance in m\n",
    "  'tiltazimuth': 0,\n",
    "  'tilt': 0,\n",
    "  'detrot': 0,\n",
    "  'outerangle_offset': 0.0\n",
    "}\n",
    "\n",
    "voxel_size = None\n",
    "apodize = True\n",
    "flip = False\n",
    "isosurface = None\n",
    "\n",
    "# Display parameters\n",
    "usetex = True  # might not work if running the notebook directly on nice or slurm\n",
    "show = True\n",
    "verbose = True\n",
    "debug = False\n",
    "\n",
    "method_det_support = \"Amplitude_variation\" # \"Isosurface\" or \"Amplitude_variation\"\n",
    "order_of_derivative = \"Gradient\" # \"Gradient\" or \"Laplacian\"\n",
    "raw_process = False # False if you want to fill the holes in the surface, True otherwise\n",
    "\n",
    "nb_facets = 22 # Expected number of facets of the particle\n",
    "top_facet_reference_index = [1,1,1]\n",
    "authorized_index = 1 # int, list of int, or list of list of 3 int\n",
    "remove_edges = True\n",
    "\n",
    "#Optional\n",
    "derivative_threshold = 0.2\n",
    "amplitude_threshold = 0.2\n",
    "nb_nghbs_min = 0\n",
    "index_to_display = None # None or list of triplet of indexes\n",
    "display_f_e_c = \"facet\" # \"facet\", \"edge\", \"corner\", \"all\", or None\n",
    "\n",
    "support_path = None\n",
    "\n",
    "# PyNX parameters\n",
    "\n",
    "# You can leave as it is\n",
    "data = (\n",
    "  metadata[\"dump_dir\"]\n",
    "  + \"/pynx_phasing/\"\n",
    "  + f\"S{metadata['scan']}_pynx_input_data.npz\"\n",
    ")\n",
    "\n",
    "mask = (\n",
    "  metadata[\"dump_dir\"]\n",
    "  + \"/pynx_phasing/\"\n",
    "  + f\"S{metadata['scan']}_pynx_input_mask.npz\"\n",
    ")\n",
    "\n",
    "data2cxi = True\n",
    "\n",
    "# support_size is the radius or half-size for the initial support. \n",
    "# Either one value (will be attributed to all dimensions), or one value \n",
    "# for each dimension. To be used in combination with support (which must \n",
    "# be different to \"auto\"). If support is \"auto\", leave support_size to\n",
    "# None.\n",
    "support = \"auto\"\n",
    "support_size = None  \n",
    "\n",
    "support_threshold = \"0.30, 0.40\"\n",
    "support_threshold_method = \"rms\"\n",
    "support_only_shrink = False\n",
    "support_update_period = 20\n",
    "support_smooth_width_begin = 2\n",
    "support_smooth_width_end = 1\n",
    "support_post_expand = \"1,-2,1\"\n",
    "psf = \"pseudo-voigt,0.5,0.1,10\"\n",
    "\n",
    "nb_raar = 1000\n",
    "nb_hio = 150\n",
    "nb_er = 150\n",
    "nb_ml = 10\n",
    "nb_run = 15\n",
    "nb_run_keep = 10\n",
    "\n",
    "zero_mask = False\n",
    "crop_output = 0\n",
    "positivity = False\n",
    "beta = 0.9\n",
    "detwin = False\n",
    "\n",
    "rebin = \"1,1,1\"\n",
    "detector_distance = det_calib_parameters[\"distance\"]\n",
    "pixel_size_detector = 55e-6\n",
    "wavelength = float(en2lam(energy) * 1e-10) # wavelength in meter\n",
    "\n",
    "verbose = 100\n",
    "output_format = \"cxi\"\n",
    "live_plot = False\n",
    "save_plot = True\n",
    "mpi = \"run\"\n",
    "\n",
    "\n",
    "# Load the parameters and parse them into the BcdiPipeline class instance \n",
    "parameters = get_parameters_from_notebook_variables(dir(), globals())\n",
    "bcdi_pipeline = BcdiPipeline(parameters=parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data: crop and center the data and compute orthogonalization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcdi_pipeline.preprocess()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PyNX phase retrieval using ESRF's p9 GPUs or another machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can update PyNX parameters before running the phasing\n",
    "\n",
    "# bcdi_pipeline.params[\"pynx\"].update(\n",
    "#     {\n",
    "#         \"rebin\": \"1,1,1\",\n",
    "#         \"support_update\"_period\": 20,\n",
    "#         \"support_threshold\": \"0.15, 0.40\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "user = os.environ[\"USER\"]\n",
    "key_file_path = os.environ[\"HOME\"] + \"/.ssh/id_rsa\"\n",
    "number_of_nodes = 2\n",
    "\n",
    "print(\n",
    "    f\"Will use the user name '{user}' \"\n",
    "    f\"and the private key file path:\\n'{key_file_path}'\"\n",
    ")\n",
    "\n",
    "bcdi_pipeline.phase_retrieval(\n",
    "    machine=\"slurm-nice-devel\",\n",
    "    # machine=\"lid01pwr9\",\n",
    "    user=user,\n",
    "    number_of_nodes=number_of_nodes,\n",
    "    key_file_path=key_file_path,\n",
    "    remove_last_results=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the phasing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcdi_pipeline.analyze_phasing_results(\n",
    "    sorting_criterion=\"mean_to_max\",\n",
    "    # plot_phasing_results=True,  # by commenting out, you turn this to False\n",
    "    # plot_amplitude=True  # by commenting out, you turn this to False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the best reconstructions decompose them into one mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose the number of best candidates you want to keep.\n",
    "number_of_best_candidates: int = 5\n",
    "\n",
    "# You can either select the best candidates by specifying the reconstruction\n",
    "# number\n",
    "bcdi_pipeline.select_best_candidates(\n",
    "    # best_runs=[10]\n",
    "    nb_of_best_sorted_runs=number_of_best_candidates\n",
    ")\n",
    "\n",
    "bcdi_pipeline.mode_decomposition()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally postprocess the data: orthogonalize, compute phase, dispacement, strain, dspacing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can update a few post-processing parameters instead of going\n",
    "# back up to the top of the notebook, ex:\n",
    "\n",
    "bcdi_pipeline.params[\"cdiutils\"].update(\n",
    "    {\n",
    "        \"support_path\": None,\n",
    "        \"isosurface\": None,\n",
    "        \"voxel_size\": 15,\n",
    "        \"flip\": False,\n",
    "        \"apodize\": True,\n",
    "        \"handle_defects\": False,\n",
    "        \"method_det_support\": \"Amplitude_variation\", #\"Isosurface\" or \"Amplitude_variation\"\n",
    "        \"order_of_derivative\": \"Gradient\", #\"Gradient\" or \"Laplacian\"\n",
    "        \"raw_process\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "bcdi_pipeline.postprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally analyse the facets of the particle and the mean strain per facet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can update a few parameters instead of going\n",
    "# back up to the top of the notebook, ex:\n",
    "\n",
    "bcdi_pipeline.params[\"cdiutils\"].update(\n",
    "    {\n",
    "        \"support_path\": None,\n",
    "        \"remove_edges\": True,\n",
    "        \"nb_facets\": 22,\n",
    "        \"nb_nghbs_min\": 0,\n",
    "        \"top_facet_reference_index\": [1,1,1],\n",
    "        \"authorized_index\": 1, #int, list of int, or list of list of 3 int\n",
    "        \"index_to_display\": None, # None or list of triplet of indexes\n",
    "        \"display_f_e_c\" : \"facet\" # \"facet\", \"edge\", \"corner\", \"all\", or None\n",
    "    }\n",
    ")\n",
    "\n",
    "bcdi_pipeline.facet_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_cdiutils",
   "language": "python",
   "name": "dev_cdiutils"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f8c9f7f8d10f9447c17de65ed45babc999209e89aee4cc6fcc55aaea8612438e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
